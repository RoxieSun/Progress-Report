{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare \n",
    "import numpy as np\n",
    "import pylab as pb\n",
    "import GPy as gpy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from IPython.display import display\n",
    "from scipy.fftpack import fft, ifft\n",
    "from numpy import linalg as LA\n",
    "pb.ion()\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kronoker product of matrices\n",
    "\n",
    "We hope to calcualte the kronoker product of a series of matrices efficiently. We implemented GP-grid trick\n",
    "\n",
    "From Gilboa et al, \n",
    "$(\\bigotimes_{d=1}^DA_d)b = vec([A_1 ...[A_{D-1}[A_DB]^T]^T]^T)$\n",
    "\n",
    "Here we want to calculate kronoker product of As, so we would like b to be identity matrix. \n",
    "The algorithm below implements \"Algorithm 2\" in Gilboa et al with minor modifications (i.e. in dimensions and reshapes) to accommodate b is a matrix (identity matrix), instead of a vector \n",
    "\n",
    "Inputs: D matrices $[A_1,A_2,...A_D]$, $A_D$ is a scaled covariance matrix in Dth dimension. Here b is calucalted inside the function. It is a N by N identity matrix, where N is product of number of elements in each dimension. \n",
    "    \n",
    "Outputs: $(\\bigotimes_{d=1}^DA_d)b $ = $(\\bigotimes_{d=1}^DA_d)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kron_mvprod(As):\n",
    "    \n",
    "    # generate b \n",
    "    n = 1\n",
    "    for i in np.arange(len(As)):\n",
    "        n = n * As[i].shape[0]\n",
    "    b = np.identity(n)\n",
    "    \n",
    "    x = b\n",
    "    for d in np.arange(len(As)-1,-1,-1):\n",
    "        Gd = As[d].shape[0]\n",
    "        N = x.size\n",
    "        X = np.matrix(x.reshape(Gd,N/Gd,order='F'))\n",
    "        Z = As[d]*X\n",
    "        Z = Z.T\n",
    "        x = Z.reshape(Z.size/b.shape[1],b.shape[1],order='F') \n",
    "        \n",
    "    out = x.T\n",
    "    return out;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part 1: Generate Data \n",
    "\n",
    "    Given covariance:  cov_N, cov_T, cov_C \n",
    "    i.e. cov_N is after flatterning data along the other two axis (T and C), and calculate X*X.T/(t.size*c.size)\n",
    "    \n",
    "    Parameters: sigma_N, sigma_T, sigma_C\n",
    "    i.e. sigma_N is after flatterning data along the other two axis (T and C), and calculate X*X.T\n",
    "    Requirement: tr(sigma_N) = tr(sigma_T) = tr(sigma_C)\n",
    "    \n",
    "    Goal: Infer U,V,W such that data generated from them having covariance cov_N, cov_T, cov_C as given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of samples\n",
    "n = np.arange(0,5,1)[np.newaxis].transpose() \n",
    "\n",
    "# time\n",
    "fs = 5.0  #  time step:1/fs\n",
    "t = np.arange(0,5,1/fs)[np.newaxis].transpose()\n",
    "t.size\n",
    "\n",
    "# number of cancer types\n",
    "c = np.arange(0,6,1)[np.newaxis].transpose() \n",
    "float(t.size * c.size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.0\n",
      "149.0\n",
      "149.0\n"
     ]
    }
   ],
   "source": [
    "# Given covariance matrix \n",
    "# Requirement: tr(sigma_N) = tr(sigma_T) = tr(sigma_C)\n",
    "\n",
    "# sigma_N: covariance along N\n",
    "k1 = gpy.kern.RBF(1, variance=0.2, lengthscale=1)\n",
    "cov_N = k1.K(n) #given covariance, ground truth\n",
    "sigma_N = cov_N * float(t.size * c.size-1)\n",
    "print np.matrix.trace(sigma_N)\n",
    "\n",
    "# sigma_T: covariance along T\n",
    "k2 = gpy.kern.RBF(1, variance=0.2 * n.size * float(t.size * c.size-1)/(t.size*float(n.size*c.size-1)), lengthscale=2)\n",
    "cov_T = k2.K(t) #given covariance, ground truth\n",
    "sigma_T = cov_T * float(n.size*c.size-1)\n",
    "print np.matrix.trace(sigma_T)\n",
    "\n",
    "# sigma_C: covariance along C\n",
    "k3 = gpy.kern.RBF(1, variance=0.2 * n.size * float(t.size * c.size-1)/(c.size*float(t.size*n.size-1)), lengthscale=1)\n",
    "cov_C = k3.K(c) #given covariance, ground truth\n",
    "sigma_C = cov_C * float(t.size*n.size-1)\n",
    "print np.matrix.trace(sigma_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part 2: Infer U,V,W\n",
    "\n",
    "    U/tr(U) = sigma_N/tr(sigma_N)\n",
    "\n",
    "    V/tr(V) = sigma_T/tr(sigma_T)\n",
    "\n",
    "    W/tr(W) = sigma_C/tr(sigma_C) \n",
    "\n",
    "    requirements: trace of the three need to satisfy: tr(sigma_N) = tr(U) * tr(V) * tr(W) \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "**Question**:\n",
    "        \n",
    "$x \\sim N(0, U \\otimes V \\otimes W )$\n",
    "            \n",
    "$x \\in R^{N * T * C}$\n",
    "        \n",
    "$X_N = R^{N * TC}$\n",
    "   \n",
    "\n",
    "To prove:     \n",
    "\n",
    "$tr(\\Sigma_N) = tr(U) * tr(V) * tr(W) $\n",
    "\n",
    "**Proof**: \n",
    "\n",
    "We know that in two variable case, $\\Sigma_N = tr(V)*U$. So in three variable setup, we have  $\\Sigma_N = tr(V \\otimes W) * U$\n",
    "\n",
    "From kroneker product property, $tr(V \\otimes W) = tr(V)tr(W)$, so we have $\\Sigma_N = tr(V)tr(W)*U$. Take trace on both sides, \n",
    "\n",
    "we have $tr(\\Sigma_N) = tr(U) * tr(V) * tr(W) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#U = sigma_N/np.matrix.trace(sigma_N) * np.matrix.trace(sigma_N)\n",
    "U = sigma_N/np.matrix.trace(sigma_N) *np.matrix.trace(sigma_N)\n",
    "V = sigma_T/np.matrix.trace(sigma_N) \n",
    "W = sigma_C/np.matrix.trace(sigma_N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP-trick and eigen-decomposition\n",
    "$K = K^1 \\otimes K^2 \\otimes K^3 ... \\otimes K^P$, where each $K^P = Q^PV^PQ^T$\n",
    "\n",
    "$K = QVQ^T$\n",
    "\n",
    "$V = V^1 \\otimes V^2 \\otimes V^3 ... \\otimes V^P$\n",
    "\n",
    "$Q = Q^1 \\otimes Q^2 \\otimes Q^3 ... \\otimes Q^P$\n",
    "\n",
    "Our goal is to draw sample from $Y \\sim N(0,\\Sigma)$. We can draw sample from N(0,1), reshape to proper size, perform covariance transformation. $Y = LX+\\mu$\n",
    "where $\\Sigma = LL^T$\n",
    "\n",
    "Here L = Q*sqrt(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V1, Q1 = LA.eig(W)\n",
    "V2, Q2 = LA.eig(U.T)\n",
    "V3, Q3 = LA.eig(V.T)\n",
    "\n",
    "V1 = np.diag(V1)\n",
    "V2 = np.diag(V2)\n",
    "V3 = np.diag(V3)\n",
    "\n",
    "VV = kron_mvprod([V1,V2,V3])\n",
    "QQ = kron_mvprod([Q1,Q2,Q3])\n",
    "\n",
    "L = QQ * np.sqrt(VV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimension = t.size*n.size*c.size\n",
    "Ndraws = 1000\n",
    "norm = np.random.normal(size=Ndraws*dimension).reshape(dimension, Ndraws)\n",
    "rand = np.dot(L, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_N = 0 # estimate of sigma_N\n",
    "x_T = 0 # estimate of sigma_T\n",
    "x_C = 0 # estimate of sigma_C\n",
    "\n",
    "for i in xrange(0, Ndraws-1):\n",
    "    \n",
    "    x=np.array(rand[:,i])\n",
    "    #x = np.random.multivariate_normal(np.zeros(t.size*n.size*c.size), covariance, 1)\n",
    "    \n",
    "    # reshape\n",
    "    z = x.reshape(c.size,n.size,t.size)\n",
    "    \n",
    "    # cancer type (c), # of samples (n), time (t) \n",
    "    \n",
    "    # covariance along cancer c\n",
    "    nn = float(c.size)\n",
    "    a = z[0,:,:].ravel()\n",
    "    # flatten t, n axis\n",
    "    for i in np.arange(1,nn):\n",
    "        a = np.vstack((a, z[i,:,:].ravel()))\n",
    "    x_C = x_C + np.cov(a)\n",
    "    \n",
    " \n",
    "   # covariance along number of samples n\n",
    "    nn = float(n.size)\n",
    "    \n",
    "    b = z[:,0,:].ravel()\n",
    "    # flatten t, c axis\n",
    "    for i in np.arange(1,nn):\n",
    "        b = np.vstack((b, z[:,i,:].ravel()))\n",
    "    x_N = x_N + np.cov(b)\n",
    "    \n",
    "    # covariance along time (t)\n",
    "    nn = float(t.size)\n",
    "    d = z[:,:,0].ravel()\n",
    "    # flatten n, c axis\n",
    "    for i in np.arange(1,nn):\n",
    "        d = np.vstack((d, z[:,:,i].ravel()))\n",
    "    x_T = x_T + np.cov(d)\n",
    "    \n",
    "     \n",
    "x_N = x_N/Ndraws\n",
    "x_T = x_T/Ndraws\n",
    "x_C = x_C/Ndraws"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
